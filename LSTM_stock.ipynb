{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Multi-Feature Stock Price Prediction with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a daily minimum temperature forecast project using LSTM. The goal is to input a limited sequence of time-series and obtain the following output time-series. \n",
    "\n",
    "The codes for this project is modified from [Thushan Ganegedara's Datacamp tutorial](https://www.datacamp.com/community/tutorials/lstm-python-stock-market). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background for LSTM\n",
    "The long short-term memory (LSTM) unit is an improved version of gated recurrent unit (GRU), which tries to resolve the [vanishing gradient problem](http://neuralnetworksanddeeplearning.com/chap5.html) and keep the long term \"memory\" activated.\n",
    "\n",
    "See my other [project](https://github.com/ginochen/LSTM/blob/master/LSTM_min_temp.ipynb) for a picture summary on the network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the 10 years daily minimum temperature data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Ticker Symbol Period Ending  Accounts Payable  \\\n",
      "4           4           AAP    2012-12-29      2.409453e+09   \n",
      "5           5           AAP    2013-12-28      2.609239e+09   \n",
      "6           6           AAP    2015-01-03      3.616038e+09   \n",
      "7           7           AAP    2016-01-02      3.757085e+09   \n",
      "\n",
      "   Accounts Receivable  Add'l income/expense items  After Tax ROE  \\\n",
      "4          -89482000.0                    600000.0           32.0   \n",
      "5          -32428000.0                   2698000.0           26.0   \n",
      "6          -48209000.0                   3092000.0           25.0   \n",
      "7          -21476000.0                  -7484000.0           19.0   \n",
      "\n",
      "   Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
      "4          -271182000.0      520215000.0        23.0   \n",
      "5          -195757000.0      531293000.0        40.0   \n",
      "6          -228446000.0      562945000.0         3.0   \n",
      "7          -234747000.0      603332000.0         2.0   \n",
      "\n",
      "               ...               Total Current Assets  \\\n",
      "4              ...                       3.184200e+09   \n",
      "5              ...                       3.989384e+09   \n",
      "6              ...                       4.741040e+09   \n",
      "7              ...                       4.940746e+09   \n",
      "\n",
      "   Total Current Liabilities  Total Equity  Total Liabilities  \\\n",
      "4               2.559638e+09  1.210694e+09       3.403120e+09   \n",
      "5               2.764785e+09  1.516205e+09       4.048569e+09   \n",
      "6               3.654416e+09  2.002912e+09       5.959446e+09   \n",
      "7               3.797477e+09  2.460648e+09       5.673917e+09   \n",
      "\n",
      "   Total Liabilities & Equity  Total Revenue  Treasury Stock  For Year  \\\n",
      "4                4.613814e+09   6.205003e+09     -27095000.0    2012.0   \n",
      "5                5.564774e+09   6.493814e+09    -107890000.0    2013.0   \n",
      "6                7.962358e+09   9.843861e+09    -113044000.0    2014.0   \n",
      "7                8.134565e+09   9.737018e+09    -119709000.0    2015.0   \n",
      "\n",
      "   Earnings Per Share  Estimated Shares Outstanding  \n",
      "4                5.29                  7.328355e+07  \n",
      "5                5.36                  7.308918e+07  \n",
      "6                6.75                  7.315926e+07  \n",
      "7                6.45                  7.339504e+07  \n",
      "\n",
      "[4 rows x 79 columns]\n",
      "<bound method DataFrame.count of    Unnamed: 0 Ticker Symbol Period Ending  Accounts Payable  \\\n",
      "4           4           AAP    2012-12-29      2.409453e+09   \n",
      "5           5           AAP    2013-12-28      2.609239e+09   \n",
      "6           6           AAP    2015-01-03      3.616038e+09   \n",
      "7           7           AAP    2016-01-02      3.757085e+09   \n",
      "\n",
      "   Accounts Receivable  Add'l income/expense items  After Tax ROE  \\\n",
      "4          -89482000.0                    600000.0           32.0   \n",
      "5          -32428000.0                   2698000.0           26.0   \n",
      "6          -48209000.0                   3092000.0           25.0   \n",
      "7          -21476000.0                  -7484000.0           19.0   \n",
      "\n",
      "   Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
      "4          -271182000.0      520215000.0        23.0   \n",
      "5          -195757000.0      531293000.0        40.0   \n",
      "6          -228446000.0      562945000.0         3.0   \n",
      "7          -234747000.0      603332000.0         2.0   \n",
      "\n",
      "               ...               Total Current Assets  \\\n",
      "4              ...                       3.184200e+09   \n",
      "5              ...                       3.989384e+09   \n",
      "6              ...                       4.741040e+09   \n",
      "7              ...                       4.940746e+09   \n",
      "\n",
      "   Total Current Liabilities  Total Equity  Total Liabilities  \\\n",
      "4               2.559638e+09  1.210694e+09       3.403120e+09   \n",
      "5               2.764785e+09  1.516205e+09       4.048569e+09   \n",
      "6               3.654416e+09  2.002912e+09       5.959446e+09   \n",
      "7               3.797477e+09  2.460648e+09       5.673917e+09   \n",
      "\n",
      "   Total Liabilities & Equity  Total Revenue  Treasury Stock  For Year  \\\n",
      "4                4.613814e+09   6.205003e+09     -27095000.0    2012.0   \n",
      "5                5.564774e+09   6.493814e+09    -107890000.0    2013.0   \n",
      "6                7.962358e+09   9.843861e+09    -113044000.0    2014.0   \n",
      "7                8.134565e+09   9.737018e+09    -119709000.0    2015.0   \n",
      "\n",
      "   Earnings Per Share  Estimated Shares Outstanding  \n",
      "4                5.29                  7.328355e+07  \n",
      "5                5.36                  7.308918e+07  \n",
      "6                6.75                  7.315926e+07  \n",
      "7                6.45                  7.339504e+07  \n",
      "\n",
      "[4 rows x 79 columns]>\n",
      "              date symbol        open       close         low        high  \\\n",
      "253     2010-01-04    AAP   40.700001   40.380001   40.360001   41.040001   \n",
      "720     2010-01-05    AAP   40.299999   40.139999   39.720001   40.310001   \n",
      "1188    2010-01-06    AAP   40.049999   40.490002   40.049999   40.779999   \n",
      "1656    2010-01-07    AAP   39.549999   40.480000   39.549999   40.540001   \n",
      "2124    2010-01-08    AAP   40.250000   40.639999   40.110001   40.820000   \n",
      "2592    2010-01-11    AAP   40.720001   40.240002   40.090000   40.799999   \n",
      "3060    2010-01-12    AAP   39.430000   39.540001   38.820000   39.720001   \n",
      "3528    2010-01-13    AAP   39.500000   40.090000   39.410000   40.150002   \n",
      "3996    2010-01-14    AAP   39.939999   39.560001   39.250000   39.939999   \n",
      "4464    2010-01-15    AAP   39.340000   39.310001   39.169998   39.660000   \n",
      "4932    2010-01-19    AAP   39.299999   39.500000   39.049999   39.520000   \n",
      "5400    2010-01-20    AAP   38.750000   39.160000   38.380001   39.380001   \n",
      "5868    2010-01-21    AAP   39.340000   39.230000   38.950001   39.650002   \n",
      "6336    2010-01-22    AAP   39.130001   39.740002   39.130001   40.639999   \n",
      "6804    2010-01-25    AAP   40.009998   40.500000   40.000000   40.599998   \n",
      "7272    2010-01-26    AAP   40.480000   40.549999   40.259998   41.000000   \n",
      "7740    2010-01-27    AAP   40.590000   40.590000   39.950001   40.740002   \n",
      "8208    2010-01-28    AAP   40.500000   39.770000   39.669998   40.500000   \n",
      "8676    2010-01-29    AAP   39.990002   39.450001   39.419998   40.400002   \n",
      "9144    2010-02-01    AAP   39.549999   40.490002   39.500000   40.509998   \n",
      "9612    2010-02-02    AAP   40.459999   41.189999   40.459999   41.349998   \n",
      "10080   2010-02-03    AAP   41.189999   41.189999   40.930000   41.380001   \n",
      "10548   2010-02-04    AAP   41.060001   40.930000   40.689999   41.730000   \n",
      "11016   2010-02-05    AAP   41.009998   40.720001   40.020000   41.130001   \n",
      "11484   2010-02-08    AAP   41.009998   40.810001   40.619999   41.740002   \n",
      "11952   2010-02-09    AAP   41.150002   41.570000   40.770000   41.720001   \n",
      "12420   2010-02-10    AAP   41.389999   42.330002   41.369999   42.849998   \n",
      "12888   2010-02-11    AAP   42.410000   42.549999   42.130001   43.099998   \n",
      "13356   2010-02-12    AAP   42.369999   42.810001   42.000000   42.810001   \n",
      "13824   2010-02-16    AAP   42.900002   42.630001   42.369999   42.980000   \n",
      "...            ...    ...         ...         ...         ...         ...   \n",
      "836266  2016-11-17    AAP  163.440002  166.320007  162.339996  166.970001   \n",
      "836766  2016-11-18    AAP  166.119995  162.570007  162.229996  166.729996   \n",
      "837266  2016-11-21    AAP  162.750000  166.899994  162.000000  167.389999   \n",
      "837766  2016-11-22    AAP  167.630005  170.289993  167.070007  170.979996   \n",
      "838266  2016-11-23    AAP  170.259995  171.039993  168.649994  171.509995   \n",
      "838766  2016-11-25    AAP  171.690002  170.860001  170.130005  172.020004   \n",
      "839266  2016-11-28    AAP  171.149994  170.770004  170.550003  174.309998   \n",
      "839766  2016-11-29    AAP  172.339996  169.800003  169.699997  173.490005   \n",
      "840266  2016-11-30    AAP  169.479996  169.720001  168.410004  170.669998   \n",
      "840766  2016-12-01    AAP  169.179993  170.759995  167.320007  171.570007   \n",
      "841266  2016-12-02    AAP  170.460007  170.139999  169.880005  171.979996   \n",
      "841766  2016-12-05    AAP  171.440002  170.529999  169.960007  171.960007   \n",
      "842266  2016-12-06    AAP  170.179993  173.309998  169.850006  173.759995   \n",
      "842766  2016-12-07    AAP  172.380005  176.779999  172.380005  177.000000   \n",
      "843266  2016-12-08    AAP  176.410004  176.520004  175.179993  177.830002   \n",
      "843766  2016-12-09    AAP  176.050003  175.580002  173.960007  177.320007   \n",
      "844266  2016-12-12    AAP  174.210007  173.000000  171.759995  175.649994   \n",
      "844766  2016-12-13    AAP  173.259995  171.869995  171.149994  174.949997   \n",
      "845266  2016-12-14    AAP  173.029999  171.509995  169.889999  174.289993   \n",
      "845766  2016-12-15    AAP  171.619995  172.919998  171.009995  173.449997   \n",
      "846266  2016-12-16    AAP  173.360001  171.910004  171.169998  173.990005   \n",
      "846766  2016-12-19    AAP  171.610001  173.820007  171.610001  175.550003   \n",
      "847266  2016-12-20    AAP  173.820007  175.630005  172.220001  176.330002   \n",
      "847766  2016-12-21    AAP  174.759995  173.509995  173.309998  175.470001   \n",
      "848266  2016-12-22    AAP  172.699997  170.389999  169.690002  173.410004   \n",
      "848766  2016-12-23    AAP  170.690002  170.889999  170.000000  172.080002   \n",
      "849266  2016-12-27    AAP  170.720001  171.839996  170.720001  172.750000   \n",
      "849766  2016-12-28    AAP  172.009995  170.419998  170.350006  172.929993   \n",
      "850266  2016-12-29    AAP  170.080002  170.279999  169.460007  171.080002   \n",
      "850766  2016-12-30    AAP  171.320007  169.119995  168.600006  172.000000   \n",
      "\n",
      "           volume  \n",
      "253     1701700.0  \n",
      "720     1932400.0  \n",
      "1188    1406200.0  \n",
      "1656    1256800.0  \n",
      "2124     960300.0  \n",
      "2592    1038400.0  \n",
      "3060    1910800.0  \n",
      "3528     810000.0  \n",
      "3996    1157600.0  \n",
      "4464     738900.0  \n",
      "4932    1295000.0  \n",
      "5400    1865000.0  \n",
      "5868    1297400.0  \n",
      "6336    2629300.0  \n",
      "6804    1396900.0  \n",
      "7272    1084100.0  \n",
      "7740    1203200.0  \n",
      "8208    1206000.0  \n",
      "8676     948500.0  \n",
      "9144    1106600.0  \n",
      "9612    1296200.0  \n",
      "10080   1147600.0  \n",
      "10548   1611600.0  \n",
      "11016   1313200.0  \n",
      "11484   1721900.0  \n",
      "11952   1030000.0  \n",
      "12420   1858600.0  \n",
      "12888   1548600.0  \n",
      "13356   1509800.0  \n",
      "13824   1721200.0  \n",
      "...           ...  \n",
      "836266  1496400.0  \n",
      "836766  1226600.0  \n",
      "837266   764100.0  \n",
      "837766  1387900.0  \n",
      "838266   982000.0  \n",
      "838766   405600.0  \n",
      "839266  1023100.0  \n",
      "839766   639600.0  \n",
      "840266   827500.0  \n",
      "840766   858700.0  \n",
      "841266   487000.0  \n",
      "841766   740300.0  \n",
      "842266   753400.0  \n",
      "842766   774500.0  \n",
      "843266   796800.0  \n",
      "843766   521500.0  \n",
      "844266  1088800.0  \n",
      "844766  1015200.0  \n",
      "845266  1458000.0  \n",
      "845766   662900.0  \n",
      "846266   891700.0  \n",
      "846766   548400.0  \n",
      "847266  1246000.0  \n",
      "847766   454700.0  \n",
      "848266   946100.0  \n",
      "848766   334200.0  \n",
      "849266   508700.0  \n",
      "849766   357100.0  \n",
      "850266   431400.0  \n",
      "850766   489300.0  \n",
      "\n",
      "[1762 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker Symbol</th>\n",
       "      <th>Period Ending</th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Current Assets</th>\n",
       "      <th>Total Current Liabilities</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>Total Liabilities</th>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Treasury Stock</th>\n",
       "      <th>For Year</th>\n",
       "      <th>Earnings Per Share</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>3.068000e+09</td>\n",
       "      <td>-222000000.0</td>\n",
       "      <td>-1.961000e+09</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.888000e+09</td>\n",
       "      <td>4.695000e+09</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.072000e+09</td>\n",
       "      <td>9.011000e+09</td>\n",
       "      <td>-7.987000e+09</td>\n",
       "      <td>2.489100e+10</td>\n",
       "      <td>1.690400e+10</td>\n",
       "      <td>2.485500e+10</td>\n",
       "      <td>-367000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>3.350000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>4.975000e+09</td>\n",
       "      <td>-93000000.0</td>\n",
       "      <td>-2.723000e+09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-3.114000e+09</td>\n",
       "      <td>1.059200e+10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432300e+10</td>\n",
       "      <td>1.380600e+10</td>\n",
       "      <td>-2.731000e+09</td>\n",
       "      <td>4.500900e+10</td>\n",
       "      <td>4.227800e+10</td>\n",
       "      <td>2.674300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>1.630222e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>4.668000e+09</td>\n",
       "      <td>-160000000.0</td>\n",
       "      <td>-1.500000e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-5.311000e+09</td>\n",
       "      <td>1.513500e+10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175000e+10</td>\n",
       "      <td>1.340400e+10</td>\n",
       "      <td>2.021000e+09</td>\n",
       "      <td>4.120400e+10</td>\n",
       "      <td>4.322500e+10</td>\n",
       "      <td>4.265000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>7.169154e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>5.102000e+09</td>\n",
       "      <td>352000000.0</td>\n",
       "      <td>-7.080000e+08</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-6.151000e+09</td>\n",
       "      <td>1.159100e+10</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.985000e+09</td>\n",
       "      <td>1.360500e+10</td>\n",
       "      <td>5.635000e+09</td>\n",
       "      <td>4.278000e+10</td>\n",
       "      <td>4.841500e+10</td>\n",
       "      <td>4.099000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>11.39</td>\n",
       "      <td>6.681299e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAP</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>2.409453e+09</td>\n",
       "      <td>-89482000.0</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-2.711820e+08</td>\n",
       "      <td>5.202150e+08</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.184200e+09</td>\n",
       "      <td>2.559638e+09</td>\n",
       "      <td>1.210694e+09</td>\n",
       "      <td>3.403120e+09</td>\n",
       "      <td>4.613814e+09</td>\n",
       "      <td>6.205003e+09</td>\n",
       "      <td>-27095000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>7.328355e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Ticker Symbol Period Ending  Accounts Payable  \\\n",
       "0           0           AAL    2012-12-31      3.068000e+09   \n",
       "1           1           AAL    2013-12-31      4.975000e+09   \n",
       "2           2           AAL    2014-12-31      4.668000e+09   \n",
       "3           3           AAL    2015-12-31      5.102000e+09   \n",
       "4           4           AAP    2012-12-29      2.409453e+09   \n",
       "\n",
       "   Accounts Receivable  Add'l income/expense items  After Tax ROE  \\\n",
       "0         -222000000.0               -1.961000e+09           23.0   \n",
       "1          -93000000.0               -2.723000e+09           67.0   \n",
       "2         -160000000.0               -1.500000e+08          143.0   \n",
       "3          352000000.0               -7.080000e+08          135.0   \n",
       "4          -89482000.0                6.000000e+05           32.0   \n",
       "\n",
       "   Capital Expenditures  Capital Surplus  Cash Ratio  \\\n",
       "0         -1.888000e+09     4.695000e+09        53.0   \n",
       "1         -3.114000e+09     1.059200e+10        75.0   \n",
       "2         -5.311000e+09     1.513500e+10        60.0   \n",
       "3         -6.151000e+09     1.159100e+10        51.0   \n",
       "4         -2.711820e+08     5.202150e+08        23.0   \n",
       "\n",
       "               ...               Total Current Assets  \\\n",
       "0              ...                       7.072000e+09   \n",
       "1              ...                       1.432300e+10   \n",
       "2              ...                       1.175000e+10   \n",
       "3              ...                       9.985000e+09   \n",
       "4              ...                       3.184200e+09   \n",
       "\n",
       "   Total Current Liabilities  Total Equity  Total Liabilities  \\\n",
       "0               9.011000e+09 -7.987000e+09       2.489100e+10   \n",
       "1               1.380600e+10 -2.731000e+09       4.500900e+10   \n",
       "2               1.340400e+10  2.021000e+09       4.120400e+10   \n",
       "3               1.360500e+10  5.635000e+09       4.278000e+10   \n",
       "4               2.559638e+09  1.210694e+09       3.403120e+09   \n",
       "\n",
       "   Total Liabilities & Equity  Total Revenue  Treasury Stock  For Year  \\\n",
       "0                1.690400e+10   2.485500e+10    -367000000.0    2012.0   \n",
       "1                4.227800e+10   2.674300e+10             0.0    2013.0   \n",
       "2                4.322500e+10   4.265000e+10             0.0    2014.0   \n",
       "3                4.841500e+10   4.099000e+10             0.0    2015.0   \n",
       "4                4.613814e+09   6.205003e+09     -27095000.0    2012.0   \n",
       "\n",
       "   Earnings Per Share  Estimated Shares Outstanding  \n",
       "0               -5.60                  3.350000e+08  \n",
       "1              -11.25                  1.630222e+08  \n",
       "2                4.02                  7.169154e+08  \n",
       "3               11.39                  6.681299e+08  \n",
       "4                5.29                  7.328355e+07  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "series_fund = pd.read_csv('nyse/fundamentals.csv')\n",
    "#print(series_fund.columns)\n",
    "print(series_fund[series_fund['Ticker Symbol']=='AAP'])\n",
    "print(series_fund[series_fund['Ticker Symbol']=='AAP'].count)\n",
    "#series_price = pd.read_csv('nyse/prices-split-adjusted.csv', error_bad_lines=False)\n",
    "series_price = pd.read_csv('nyse/prices.csv')\n",
    "print(series_price[series_price['symbol']=='AAP'])\n",
    "#series.rename(columns={'Daily minimum temperatures in Melbourne, Australia, 1981-1990':'mint'},inplace=True) # rename minimum temp to 'mint'\n",
    "#y = pd.to_numeric(series[\"mint\"],downcast='float')\n",
    "#y.index = pd.DatetimeIndex(start='1981-01-01',end='1990-12-31',freq='d')\n",
    "#freq=365 # sampling freq\n",
    "#train, valid = series_price[:freq*9], series_price[freq*9:]\n",
    "#train.index, valid.index = y.index[:freq*9], y.index[freq*9:]\n",
    "#print(series_price.head(35), series_fund[]\n",
    "series_fund.head(5)\n",
    "#series_fund.iloc[series_fund['Ticker Symbol']=='AAPL',:]\n",
    "#series_fund.iloc[series_fund['Ticker Symbol']=='AAPL']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_dim=3, output_dim=128,  return_sequences=True)) # set return_sequences to True to return the \n",
    "# full history of hidden state outputs at all times (i.e. the shape of output is (n_samples, n_timestamps, n_outdims)), \n",
    "# or the return value contains only the output at the last timestamp (i.e. the shape will be (n_samples, n_outdims)), \n",
    "# which is invalid as the input of the next LSTM layer. \n",
    "#\n",
    "# lstm1, state_h, state_c = LSTM(128, return_sequences=True, return_state=True) \n",
    "# with return_state set to true, this returns the sequential hidden states, final hidden state and final cell states. \n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(input_dim=128, output_dim=1))\n",
    "model.add(Activation('linear')) # this essentially applies no activation, a(x)=x, which returns the Dense output directly\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=50)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class to generate training data, i.e., batches of sequenced data for the input and output (set the random indexing distance for output time series to within 3 indices, this may be a reasonable guess from mid-latitude weather patterns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class DataGeneratorSeq(object):\n",
    "    # prices: total training time-series data\n",
    "    # batch_size: the length of a batch/sequence\n",
    "    # num_unroll: sampled number of batches/sequences\n",
    "    # segments: total number of segments in a series that is divided by the batch_size\n",
    "    \n",
    "    def __init__(self,prices,batch_size,num_unroll):\n",
    "        self._prices = prices\n",
    "        self._prices_length = len(self._prices) - num_unroll\n",
    "        self._batch_size = batch_size\n",
    "        self._num_unroll = num_unroll\n",
    "        self._segments = self._prices_length //self._batch_size\n",
    "        self._cursor = [offset * self._segments for offset in range(self._batch_size)]\n",
    "\n",
    "    def next_batch(self):\n",
    "\n",
    "        batch_data = np.zeros((self._batch_size),dtype=np.float32)\n",
    "        batch_labels = np.zeros((self._batch_size),dtype=np.float32)\n",
    "\n",
    "        for b in range(self._batch_size):\n",
    "            if self._cursor[b]+1>=self._prices_length:\n",
    "                #self._cursor[b] = b * self._segments\n",
    "                self._cursor[b] = np.random.randint(0,(b+1)*self._segments)\n",
    "\n",
    "            batch_data[b] = self._prices[self._cursor[b]]\n",
    "            batch_labels[b]= self._prices[self._cursor[b]+np.random.randint(0,3)] \n",
    "            # draw one random index for the output within 3 indices\n",
    "\n",
    "            self._cursor[b] = (self._cursor[b]+1)%self._prices_length\n",
    "\n",
    "        return batch_data,batch_labels\n",
    "\n",
    "    def unroll_batches(self):\n",
    "\n",
    "        unroll_data,unroll_labels = [],[]\n",
    "        init_data, init_label = None,None\n",
    "        for ui in range(self._num_unroll):\n",
    "\n",
    "            data, labels = self.next_batch()    \n",
    "\n",
    "            unroll_data.append(data)\n",
    "            unroll_labels.append(labels)\n",
    "\n",
    "        return unroll_data, unroll_labels\n",
    "\n",
    "    def reset_indices(self):\n",
    "        for b in range(self._batch_size):\n",
    "            self._cursor[b] = np.random.randint(0,min((b+1)*self._segments,self._prices_length-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the training data batches look like? Set batchsize to 9 samples and 4 time steps, so it'll sample all the first 4 days in January and the prediction output is the randomly indexed (0-3 days) following days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first index of each batch: [0, 364, 728, 1092, 1456, 1820, 2184, 2548, 2912]\n",
      "total number of segments: 364\n",
      "1981-01-01    20.700001\n",
      "1981-01-02    17.900000\n",
      "1981-01-03    18.799999\n",
      "1981-01-04    14.600000\n",
      "1981-01-05    15.800000\n",
      "Freq: D, Name: mint, dtype: float32\n",
      "\n",
      "\n",
      "Unrolled index 0\n",
      "\tInputs:  [20.7 17.4 17.7 16.1 12.  13.3 10.5 11.2 15.2]\n",
      "\n",
      "\tOutputs: [17.9 15.  17.7 18.  12.  13.3 14.6 11.2 15.2]\n",
      "\n",
      "\n",
      "Unrolled index 1\n",
      "\tInputs:  [17.9 17.  16.3 20.4 12.6 11.5 14.7 12.1 17.3]\n",
      "\n",
      "\tOutputs: [14.6 13.5 15.  19.5 12.6 11.5 14.2 16.2 17.3]\n",
      "\n",
      "\n",
      "Unrolled index 2\n",
      "\tInputs:  [18.8 15.  18.4 18.  16.  10.8 14.6 12.7 19.8]\n",
      "\n",
      "\tOutputs: [14.6 15.2 10.9 17.1 16.4 10.8 13.2 14.2  9.5]\n",
      "\n",
      "\n",
      "Unrolled index 3\n",
      "\tInputs:  [14.6 13.5 15.  19.5 16.4 12.  14.2 16.2 15.8]\n",
      "\n",
      "\tOutputs: [15.8 13.5 15.  19.5 13.3 12.  11.7 14.3 15.8]\n"
     ]
    }
   ],
   "source": [
    "tstep = 4\n",
    "batchsize = 9 # a batch contains the samples, not the dimensionality, so each input sample is fed forward once at a time to get an output\n",
    "dg = DataGeneratorSeq(train,batchsize,tstep)\n",
    "print('the first index of each batch: %s'%str(dg._cursor))\n",
    "print('total number of segments: %d'%dg._segments)\n",
    "print(dg._prices.head(5))\n",
    "\n",
    "u_data, u_labels = dg.unroll_batches()\n",
    "\n",
    "for ui,(dat,lbl) in enumerate(zip(u_data,u_labels)):   \n",
    "    print('\\n\\nUnrolled index %d'%ui)\n",
    "    dat_ind = dat\n",
    "    lbl_ind = lbl\n",
    "    print('\\tInputs: ',dat )\n",
    "    print('\\n\\tOutputs:',lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Unrolled index` is the timesteps, so 20.7, 17.9, 18.8, 14.6 is the four LSTM timesteps of `Inputs` fed forward. The associated four `Outputs` are the randomly indexed (within 0-3 days) four timesteps 20.7, 17.9, 18,8, 15.8. Notice the leading 3 steps of outputs were randomly sampled but identical to the leading 3 steps of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "D = 1 # Dimensionality/Feature of the data. Since the time-series is 1-D this would be 1\n",
    "num_unrollings = 10 # Number of time steps you look into the future.\n",
    "batch_size = 500 # Number of samples in a batch\n",
    "num_nodes = [128,128,128] # Number of hidden nodes in each layer/cell of the deep LSTM stack we're using\n",
    "n_layers = len(num_nodes) # number of layers\n",
    "dropout = 0.2 # dropout amount\n",
    "\n",
    "tf.reset_default_graph() # This is important in case you run this multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining \"tensorized\" training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data.\n",
    "train_inputs, train_outputs = [],[]\n",
    "\n",
    "# You unroll the input over time defining placeholders for each time step\n",
    "for ui in range(num_unrollings):\n",
    "    train_inputs.append(tf.placeholder(tf.float32, shape=[batch_size,D],name='train_inputs_%d'%ui))\n",
    "    train_outputs.append(tf.placeholder(tf.float32, shape=[batch_size,1], name = 'train_outputs_%d'%ui))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining LSTM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM cells with Xavier initializer. \n",
    "# Which sets small variance for the weights to avoid vanishing/exploding gradient problem \n",
    "# when using tanh as activation function\n",
    "lstm_cells = [ tf.contrib.rnn.LSTMCell(num_units=num_nodes[li],\n",
    "                            state_is_tuple=True,\n",
    "                            initializer= tf.contrib.layers.xavier_initializer()\n",
    "                           )\n",
    "               for li in range(n_layers) ]\n",
    "\n",
    "# dropout regularization is to reduce overfit (instead of waiting for backprop to find the near zero \n",
    "# weights for regularizatoin, dropout regularization draws a uniformly dist sample between 0 and 1 and \n",
    "# eliminate the nodes with probablity smaller than some keep_prob)\n",
    "drop_lstm_cells = [ tf.contrib.rnn.DropoutWrapper(\n",
    "                   lstm, input_keep_prob=1.0,output_keep_prob=1.0-dropout, state_keep_prob=1.0-dropout) \n",
    "                   for lstm in lstm_cells ]\n",
    "\n",
    "# create the sequential RNN Cells with dropout regularization\n",
    "multi_cell_drop = tf.contrib.rnn.MultiRNNCell(drop_lstm_cells)\n",
    "\n",
    "# create the sequential RNN Cells without dropout regularization\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "\n",
    "# The output regression weights that transforms the final hidden layers of LSTM\n",
    "w = tf.get_variable('w',shape=[num_nodes[-1], 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.get_variable('b',initializer=tf.random_uniform([1],-0.1,0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform LSTM hidden to output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor size [nt, batch_size, D]: (10, 500, 1)\n",
      "LSTM hidden tensor size [nt batch_size, hidden nodes]: (10, 500, 128)\n",
      "LSTM hidden tensor size reshaped [batch_size*nt, hidden nodes]: (5000, 128)\n",
      "Final output (w*LSTM_hidden_nodes + b) tensor size [batch_size*nt, hidden nodes]*[hidden nodes,1]=[batch_size*nt,1]: (5000, 1)\n",
      "Split final output into \"nt\" of [batch_size,1] tensors\n"
     ]
    }
   ],
   "source": [
    "# Create cell state 'c' and hidden state 'h' variables to maintain the state of the LSTM\n",
    "c, h = [],[]\n",
    "initial_state = []\n",
    "for li in range(n_layers):\n",
    "    c.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=False))\n",
    "    h.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=False))\n",
    "    initial_state.append(tf.contrib.rnn.LSTMStateTuple(c[li], h[li]))\n",
    "\n",
    "# Do several tensor transformations, because the function dynamic_rnn requires the output to be of\n",
    "# a specific format. Read more at: https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "# make input into a tensor of size [ntsteps, batch_size, D]\n",
    "all_inputs = tf.concat([tf.expand_dims(t,0) for t in train_inputs],axis=0) \n",
    "print('Input tensor size [nt, batch_size, D]: '+str(all_inputs.shape))\n",
    "\n",
    "# all_outputs is [seq_length, batch_size, num_nodes]\n",
    "all_lstm_outputs, state = tf.nn.dynamic_rnn(\n",
    "    multi_cell_drop, all_inputs, initial_state=tuple(initial_state),\n",
    "    time_major = True, dtype=tf.float32)\n",
    "print('LSTM hidden tensor size [nt batch_size, hidden nodes]: '+str(all_lstm_outputs.shape))\n",
    "\n",
    "all_lstm_outputs = tf.reshape(all_lstm_outputs, [batch_size*num_unrollings,num_nodes[-1]])\n",
    "print('LSTM hidden tensor size reshaped [batch_size*nt, hidden nodes]: '+str(all_lstm_outputs.shape))\n",
    "\n",
    "all_outputs = tf.nn.xw_plus_b(all_lstm_outputs,w,b)\n",
    "print('Final output (w*LSTM_hidden_nodes + b) tensor size ' \n",
    "      '[batch_size*nt, hidden nodes]*[hidden nodes,1]=[batch_size*nt,1]: '+str(all_outputs.shape))\n",
    "\n",
    "split_outputs = tf.split(all_outputs,num_unrollings,axis=0)\n",
    "print('Split final output into \"nt\" of [batch_size,1] tensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Calculation and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-8-f0b050d07929>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-f0b050d07929>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    for ui in range(num_unrollings):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# When calculating the loss you need to be careful about the exact form, because you calculate\n",
    "# loss of all the unrolled steps at the same time\n",
    "# Therefore, take the mean error or each batch and get the sum of that over all the unrolled steps\n",
    "\n",
    "print('Defining training Loss')\n",
    "loss = 0.0\n",
    "with tf.control_dependencies([tf.assign(c[li], state[li][0]) for li in range(n_layers)]+\n",
    "                             [tf.assign(h[li], state[li][1]) for li in range(n_layers)]):\n",
    "for ui in range(num_unrollings):\n",
    "    loss += tf.reduce_mean(0.5*(split_outputs[ui]-train_outputs[ui])**2)\n",
    "\n",
    "print('Learning rate decay operations')\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "inc_gstep = tf.assign(global_step,global_step + 1)\n",
    "tf_learning_rate = tf.placeholder(shape=None,dtype=tf.float32)\n",
    "tf_min_learning_rate = tf.placeholder(shape=None,dtype=tf.float32)\n",
    "\n",
    "learning_rate = tf.maximum(\n",
    "    tf.train.exponential_decay(tf_learning_rate, global_step, decay_steps=1, decay_rate=0.5, staircase=True),\n",
    "    tf_min_learning_rate)\n",
    "\n",
    "# Optimizer.\n",
    "print('TF Optimization operations')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v))\n",
    "\n",
    "print('\\tAll done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* [Understanding LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [Why use LSTM? (paper collection)](http://people.idsia.ch/~juergen/rnn.html)\n",
    "* [LSTM for stock prediction, referenece project](https://www.datacamp.com/community/tutorials/lstm-python-stock-market)\n",
    "* [vanishing gradient problem explained](http://neuralnetworksanddeeplearning.com/chap5.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
